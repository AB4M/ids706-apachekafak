import os, pandas as pd, time
import streamlit as st
from sqlalchemy import create_engine, text

PG_HOST = os.getenv("PG_HOST", "postgres")
PG_PORT = os.getenv("PG_PORT", "5432")
PG_DB = os.getenv("PG_DB", "streamdb")
PG_USER = os.getenv("PG_USER", "stream")
PG_PASSWORD = os.getenv("PG_PASSWORD", "stream")

@st.cache_resource
def get_engine():
    url = f"postgresql+psycopg2://{PG_USER}:{PG_PASSWORD}@{PG_HOST}:{PG_PORT}/{PG_DB}"
    return create_engine(url, pool_pre_ping=True)

engine = get_engine()

st.set_page_config(page_title="IoT Streaming Dashboard", layout="wide")
st.title("ğŸ¢ IoT å®æ—¶æ¥¼å®‡ç›‘æµ‹ï¼ˆKafka â†’ Postgres â†’ Streamlitï¼‰")

# è‡ªåŠ¨åˆ·æ–°ï¼ˆæ¯ 2sï¼‰
st_autorefresh = st.experimental_rerun if False else None
st.experimental_set_query_params(ts=int(time.time()))  # é˜²æ­¢æµè§ˆå™¨ç¼“å­˜
st.sidebar.write("â± è‡ªåŠ¨åˆ·æ–°ï¼šæ¯ 2 ç§’")

@st.cache_data(ttl=2)
def load_recent(limit_rows=5000):
    q = text("""
        WITH latest AS (
            SELECT DISTINCT ON (device_id)
                device_id, event_ts, temperature_c, humidity_pct, air_quality_index,
                battery_pct, status, latitude, longitude, building, floor, latency_ms
            FROM iot_readings
            ORDER BY device_id, event_ts DESC
        )
        SELECT * FROM latest;
    """)
    df_latest = pd.read_sql(q, engine)

    q2 = text("""
        SELECT event_ts, building, AVG(temperature_c) AS avg_temp,
               AVG(humidity_pct) AS avg_hum, AVG(latency_ms) AS avg_latency,
               COUNT(*) AS events
        FROM iot_readings
        WHERE event_ts > NOW() - INTERVAL '30 minutes'
        GROUP BY event_ts, building
        ORDER BY event_ts DESC
        LIMIT :limit_rows
    """)
    df_timeseries = pd.read_sql(q2, engine, params={"limit_rows": limit_rows})
    return df_latest, df_timeseries

df_latest, df_ts = load_recent()

# é¡¶éƒ¨ KPI
col1, col2, col3, col4 = st.columns(4)
col1.metric("åœ¨çº¿è®¾å¤‡æ•°", int((df_latest["status"] == "online").sum()))
col2.metric("æœ€è¿‘30åˆ†é’Ÿäº‹ä»¶æ•°", int(df_ts["events"].sum()) if not df_ts.empty else 0)
col3.metric("å¹³å‡å»¶è¿Ÿ(ms)", int(df_ts["avg_latency"].mean()) if not df_ts.empty else 0)
col4.metric("ä½ç”µé‡(â‰¤20%)", int((df_latest["battery_pct"] <= 20).sum()))

st.markdown("---")

# å·¦ï¼šæ—¶åºå›¾ï¼›å³ï¼šåœ°å›¾ä¸çŠ¶æ€åˆ†å¸ƒ
lc, rc = st.columns([2, 1])

with lc:
    st.subheader("æŒ‰æ¥¼å®æ—¶å¹³å‡æ¸©æ¹¿åº¦ï¼ˆæœ€è¿‘ 30 åˆ†é’Ÿï¼‰")
    if not df_ts.empty:
        # è½¬å®½è¡¨æ–¹ä¾¿ç»˜å›¾
        temp_pivot = df_ts.pivot_table(index="event_ts", columns="building", values="avg_temp", aggfunc="mean")
        hum_pivot = df_ts.pivot_table(index="event_ts", columns="building", values="avg_hum", aggfunc="mean")
        st.line_chart(temp_pivot.sort_index(), height=260)
        st.line_chart(hum_pivot.sort_index(), height=160)
    else:
        st.info("æš‚æ— æ•°æ®ï¼Œç­‰å¾…æµå…¥â€¦")

with rc:
    st.subheader("è®¾å¤‡åœ°å›¾ï¼ˆæœ€æ–°ä½ç½®ï¼‰")
    if not df_latest.empty and {"latitude","longitude"}.issubset(df_latest.columns):
        st.map(df_latest.rename(columns={"latitude":"lat","longitude":"lon"})[["lat","lon"]], use_container_width=True)
    else:
        st.info("æš‚æ— ä½ç½®æ•°æ®")

    st.subheader("çŠ¶æ€åˆ†å¸ƒ")
    st.bar_chart(df_latest["status"].value_counts())

st.markdown("---")
st.caption("æ•°æ®æµï¼šProducer â†’ Kafka â†’ Consumer â†’ PostgreSQL â†’ Streamlitï¼ˆ2 ç§’è‡ªåŠ¨åˆ·æ–°ï¼‰")
